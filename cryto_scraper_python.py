# -*- coding: utf-8 -*-
"""cryto_scraper_python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EotSr1ax3J_vJZxOBM3bFUFcCaVJuRpp
"""

#pandas
import pandas as pd
import os
#A slightly different case study for Python
#I will scrape daily covid 19 reports from a github repo
url = "https://raw.githubusercontent.com/datasets/covid-19/main/data/worldwide-aggregate.csv"
#read html table
new_data = pd.read_csv(url)

#drop duplicates
new_data = new_data.drop_duplicates()

#if file already exists in file path, append to it, else write afresh
if os.path.exists("data/covid_data.csv") == True:
  old = pd.read_csv("data/covid_data.csv") #read the old dataframe
  size = new_data.shape[0] - old.shape[0] #get the length between new data and old
  new_data = new_data.tail(size) #filter for the new rows different from the old
  new_data.to_csv('data/covid_data.csv', mode='a', index=False, header = False) #write
else:
  new_data.to_csv('data/covid_data.csv', index=False)